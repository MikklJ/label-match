{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils import data\n",
    "import bdd_utils\n",
    "from PIL import Image\n",
    "from utils.pad_collate import PadCollate\n",
    "from utils._utils import get_config\n",
    "\n",
    "import os, sys\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "sys.path.append(\"..\"),\n",
    "\n",
    "def __deterministic_worker_init_fn(worker_id, seed=0):\n",
    "    import random\n",
    "    import numpy\n",
    "    random.seed(seed)\n",
    "    numpy.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def get_train_labels(labels):\n",
    "    label_map = {label[0]: label[2] for label in labels }\n",
    "    return label_map\n",
    "\n",
    "class CroppedDataset(data.Dataset):\n",
    "    def __init__(self, root=\"/home/ege/datasets\", split=\"train\", dataset_size='100k', noisy=False, alterations={}, img_size=(720 , 1280), val_percent=0.2, test_percent=0.1, resize=False, crop=False, crop_size=None):\n",
    "        self.data = []\n",
    "        self.img_size = img_size\n",
    "        self.resize = resize\n",
    "        self.crop = crop\n",
    "        self.crop_size = crop_size\n",
    "        self.resize = alterations['resize']\n",
    "        self.jitter = alterations['jitter']\n",
    "        self.normalize = alterations['normalize']\n",
    "        self.split = split\n",
    "        self.noisy = noisy\n",
    "        \n",
    "        if self.noisy:\n",
    "            self.gauss_mean = alterations['gaussian_noise'][0]\n",
    "            self.gauss_std = alterations['gaussian_noise'][1]\n",
    "        self.label_map = get_train_labels(michael_labels)\n",
    "\n",
    "        # Use 2871_labels to get labels\n",
    "        if self.split == \"train\":\n",
    "            labels_file = root + \"2871_labels.json\"\n",
    "            new_split = \"train\"\n",
    "        else:\n",
    "            labels_file = root + \"2871_labels.json\"\n",
    "            new_split = \"val\"\n",
    "        \n",
    "        with open(labels_file, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            \n",
    "\n",
    "        # standard normalization for the pretrained networks\n",
    "        if 'train' in self.split:\n",
    "            self.color_transforms = transforms.Compose([\n",
    "                transforms.ColorJitter(brightness=self.jitter['brightness'], contrast=self.jitter['contrast'], saturation=self.jitter['saturation'], hue=self.jitter['hue']),\n",
    "            ])\n",
    "            self.transforms = transforms.Compose([\n",
    "                #transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=self.normalize['mean'], std=self.normalize['std'])\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Compose([\n",
    "                #transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=self.normalize['mean'], std=self.normalize['std'])])\n",
    "\n",
    "        images_folder = root + \"michael_processed\"\n",
    "        images_list = []\n",
    "        \n",
    "        # Adds all labeled images to image list\n",
    "        images_list = [key.replace(\"michael/\", \"ege/\") for key in labels]\n",
    "        label_list = [label for key, label in labels.items()]\n",
    "                                   \n",
    "        #images_list = images_list[:30000] #30000\n",
    "        for i in range(2000):\n",
    "            while True:\n",
    "                is_repeat = False\n",
    "                rand_pair = np.random.choice(np.arange(len(images_list)), size=2, replace=False)\n",
    "                \n",
    "                for pair in self.data:\n",
    "                    if pair['image_1'] == images_list[rand_pair[0]] and pair['image_2'] == images_list[rand_pair[1]]:\n",
    "                        is_repeat = True\n",
    "                \n",
    "                if is_repeat:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.data.append({\n",
    "                        'image_1': images_list[rand_pair[0]],\n",
    "                        'image_2': images_list[rand_pair[1]],\n",
    "                        'label_1': label_list[rand_pair[0]],\n",
    "                        'label_2': label_list[rand_pair[1]]\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        #print(len(self.data))\n",
    "        np.random.shuffle(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        #info = []\n",
    "        # Get raw images and labels\n",
    "        img_1 = Image.open(self.data[index]['image_1'])\n",
    "        img_2 = Image.open(self.data[index]['image_2'])\n",
    "        label_1 = self.data[index][\"label_1\"]\n",
    "        label_2 = self.data[index][\"label_2\"]\n",
    "\n",
    "        width_1, height_1 = img_1.size\n",
    "        width_2, height_2 = img_2.size\n",
    "        \n",
    "        #info.append(\"Rawmage 1 \" + str(img_1.size))\n",
    "        #info.append(\"Rawmage 2 \" + str(img_2.size))\n",
    "        \n",
    "        # Adjust heights of images\n",
    "        if self.crop:\n",
    "            img_1 = img_1.resize((int(width_1 * (160 / height_1)), 160), resample=Image.NEAREST, box=None)\n",
    "            img_2 = img_2.resize((int(width_2 * (160 / height_2)), 160), resample=Image.NEAREST, box=None)\n",
    "\n",
    "        #noise_img = noise_img[y0:y0 + self.crop_size[0], x0:x0 + self.crop_size[1]]\n",
    "        #info.append(\"Image 1 \" + str(img_1.size))\n",
    "        #info.append(\"Image 2 \" + str(img_2.size))\n",
    "        \n",
    "        width_1, height_1 = img_1.size\n",
    "        width_2, height_2 = img_2.size\n",
    "        \n",
    "        if self.crop:\n",
    "            img_1 = img_1.crop((0, 0, width_1 - width_1 % 32, height_1))\n",
    "            img_2 = img_2.crop((0, 0, width_2 - width_2 % 32, height_2))\n",
    "            \n",
    "        #info.append(\"Crop 1 \" + str(img_1.size))\n",
    "        #info.append(\"Crop 2 \" + str(img_2.size))\n",
    "\n",
    "        #print(info)\n",
    "\n",
    "        # Convert images to nparrays\n",
    "        img_1 = np.array(img_1).astype(np.float32)\n",
    "        img_2 = np.array(img_2).astype(np.float32)\n",
    "\n",
    "        # Convert images to tensors\n",
    "        img_1 = torch.from_numpy(img_1).float()\n",
    "        img_2 = torch.from_numpy(img_2).float()\n",
    "        \n",
    "        # Convert labels to numbers\n",
    "        try:\n",
    "            label_1 = [el.id for el in michael_labels if el.name == label_1][0]\n",
    "            label_2 = [el.id for el in michael_labels if el.name == label_2][0]\n",
    "        except IndexError:\n",
    "            print(label_1, label_2)\n",
    "        # Convert labels to arrays\n",
    "        label_1 = (np.array([label_1]) == np.arange(50)).astype(np.int32)\n",
    "        label_2 = (np.array([label_2]) == np.arange(50)).astype(np.int32)\n",
    "        \n",
    "        img_1 = np.transpose(img_1, (2, 0, 1))\n",
    "        img_2 = np.transpose(img_2, (2, 0, 1))\n",
    "\n",
    "        # Convert labels to tensors\n",
    "        label_1 = torch.from_numpy(label_1).float()\n",
    "        label_2 = torch.from_numpy(label_2).float()\n",
    "        \n",
    "        return img_1, img_2, label_1, label_2\n",
    "        #return self.transforms(noise_img), self.transforms(gt_img), annotation\n",
    "\n",
    "def load_data(dataset, batch_size, num_workers, split='train', deterministic=False, shuffle=False):\n",
    "    \"\"\"\n",
    "    Load the denoise dataset.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #idx = dataset.indx\n",
    "    #sampler = SubsetRandomSampler(idx)\n",
    "\n",
    "    worker_init_fn = __deterministic_worker_init_fn if deterministic else None\n",
    "\n",
    "    loader = data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle,\n",
    "                                        pin_memory=True, worker_init_fn=worker_init_fn, collate_fn=PadCollate(dim=0))\n",
    "\n",
    "    return loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 160, 32]) ; tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 128]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 96]) ; tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 64]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 288]) ; tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 64]) ; tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 288]) ; tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 64]) ; tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 192]) ; tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 160]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 224]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 32]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 128]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 224]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 224]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 32]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 192]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 256]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 192]) ; tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.Size([1, 3, 160, 288]) ; tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Config file')\n",
    "#parser.add_argument('--config', nargs='?', type=str, default='../configs/label-match.yaml', help='Specify yaml config file to use')\n",
    "#args = parser.parse_args()\n",
    "#config = get_config(args.config)\n",
    "\n",
    "config = get_config('../config/train/label-match.yaml')\n",
    "train_config = config['train_dataloaders'][0]\n",
    "dataset = CroppedDataset(split=train_config['split'], root=train_config['root'], img_size=train_config['img_size'], alterations=train_config['alterations'], crop=train_config['crop'], crop_size=train_config['crop_size'])\n",
    "# TODO: debug dataset initialization\n",
    "#loader = LoaderWrapper(noisyLoader, batch_size=train_config['batch_size'])\n",
    "trainloader = data.DataLoader(dataset, batch_size=train_config['batch_size'], num_workers=train_config['num_workers'], shuffle=train_config['shuffle'])\n",
    "\n",
    "for i, (image_1, image_2, label_1, label_2) in enumerate(trainloader):\n",
    "    #print(i, image_1, image_2, label_1, label_2)\n",
    "    if i < 10:\n",
    "        print(image_1.shape, \";\", label_1)\n",
    "        print(image_2.shape, \";\", label_2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([2]) == np.arange(32)).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Label(name='red_light', id=0, trainId=0, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_person', id=1, trainId=1, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_person', id=2, trainId=2, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='grey_car', id=3, trainId=3, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='grey_suv', id=4, trainId=4, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_light', id=5, trainId=5, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_truck', id=6, trainId=6, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_car', id=7, trainId=7, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_bicycle', id=8, trainId=8, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='grey_person', id=9, trainId=9, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_suv', id=10, trainId=10, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_bus', id=11, trainId=11, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_suv', id=12, trainId=12, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_car', id=13, trainId=13, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_suv', id=14, trainId=14, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_truck', id=15, trainId=15, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_car', id=16, trainId=16, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_bus', id=17, trainId=17, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_sign', id=18, trainId=18, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_light', id=19, trainId=19, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='grey_truck', id=20, trainId=20, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_car', id=21, trainId=21, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_truck', id=22, trainId=22, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_sign', id=23, trainId=23, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_suv', id=24, trainId=24, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_light', id=25, trainId=25, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_person', id=26, trainId=26, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_person', id=27, trainId=27, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_person', id=28, trainId=28, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_bus', id=29, trainId=29, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='stop_sign', id=30, trainId=30, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_car', id=31, trainId=31, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_suv', id=32, trainId=32, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_person', id=33, trainId=33, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_motorcycle', id=34, trainId=34, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_truck', id=35, trainId=35, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_truck', id=36, trainId=36, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='yellow_bicycle', id=37, trainId=37, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='brown_person', id=38, trainId=38, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='grey_bus', id=39, trainId=39, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_sign', id=40, trainId=40, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_bus', id=41, trainId=41, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='black_bus', id=42, trainId=42, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_car', id=43, trainId=43, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='green_suv', id=44, trainId=44, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='brown_car', id=45, trainId=45, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='red_sign', id=46, trainId=46, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='white_motorcycle', id=47, trainId=47, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_bicycle', id=48, trainId=48, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0)),\n",
       " Label(name='blue_truck', id=49, trainId=49, category='void', categoryId=0, hasInstances=False, ignoreInEval=False, color=(0, 0, 0))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el.id for el in michael_labels if el.name == 'white_truck'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
